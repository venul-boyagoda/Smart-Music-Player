{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/fer2013.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data['Usage'] == 'Training']\n",
    "test = data[data['Usage'] != 'Training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28709</th>\n",
       "      <td>0</td>\n",
       "      <td>254 254 254 254 254 249 255 160 2 58 53 70 77 ...</td>\n",
       "      <td>PublicTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28710</th>\n",
       "      <td>1</td>\n",
       "      <td>156 184 198 202 204 207 210 212 213 214 215 21...</td>\n",
       "      <td>PublicTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28711</th>\n",
       "      <td>4</td>\n",
       "      <td>69 118 61 60 96 121 103 87 103 88 70 90 115 12...</td>\n",
       "      <td>PublicTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28712</th>\n",
       "      <td>6</td>\n",
       "      <td>205 203 236 157 83 158 120 116 94 86 155 180 2...</td>\n",
       "      <td>PublicTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28713</th>\n",
       "      <td>3</td>\n",
       "      <td>87 79 74 66 74 96 77 80 80 84 83 89 102 91 84 ...</td>\n",
       "      <td>PublicTest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       emotion                                             pixels       Usage\n",
       "28709        0  254 254 254 254 254 249 255 160 2 58 53 70 77 ...  PublicTest\n",
       "28710        1  156 184 198 202 204 207 210 212 213 214 215 21...  PublicTest\n",
       "28711        4  69 118 61 60 96 121 103 87 103 88 70 90 115 12...  PublicTest\n",
       "28712        6  205 203 236 157 83 158 120 116 94 86 155 180 2...  PublicTest\n",
       "28713        3  87 79 74 66 74 96 77 80 80 84 83 89 102 91 84 ...  PublicTest"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data) :\n",
    "    y_data = keras.utils.to_categorical(data['emotion'])\n",
    "    X_data = np.zeros(shape=(len(data), 48, 48, 1))\n",
    "\n",
    "    for i, row in enumerate(data.index):\n",
    "        pixels = np.fromstring(data.loc[row, 'pixels'], dtype=int, sep=' ')\n",
    "        pixels = np.reshape(pixels, (48, 48)) \n",
    "        X_data[i, :, :, 0] = pixels / 255\n",
    "\n",
    "    return X_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.2745098 ]\n",
      "   [0.31372549]\n",
      "   [0.32156863]\n",
      "   ...\n",
      "   [0.20392157]\n",
      "   [0.16862745]\n",
      "   [0.16078431]]\n",
      "\n",
      "  [[0.25490196]\n",
      "   [0.23921569]\n",
      "   [0.22745098]\n",
      "   ...\n",
      "   [0.21960784]\n",
      "   [0.20392157]\n",
      "   [0.17254902]]\n",
      "\n",
      "  [[0.19607843]\n",
      "   [0.16862745]\n",
      "   [0.21176471]\n",
      "   ...\n",
      "   [0.19215686]\n",
      "   [0.21960784]\n",
      "   [0.18431373]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.35686275]\n",
      "   [0.25490196]\n",
      "   [0.16470588]\n",
      "   ...\n",
      "   [0.28235294]\n",
      "   [0.21960784]\n",
      "   [0.16862745]]\n",
      "\n",
      "  [[0.30196078]\n",
      "   [0.32156863]\n",
      "   [0.30980392]\n",
      "   ...\n",
      "   [0.41176471]\n",
      "   [0.2745098 ]\n",
      "   [0.18039216]]\n",
      "\n",
      "  [[0.30196078]\n",
      "   [0.28235294]\n",
      "   [0.32941176]\n",
      "   ...\n",
      "   [0.41568627]\n",
      "   [0.42745098]\n",
      "   [0.32156863]]]\n",
      "\n",
      "\n",
      " [[[0.59215686]\n",
      "   [0.58823529]\n",
      "   [0.57647059]\n",
      "   ...\n",
      "   [0.50588235]\n",
      "   [0.54901961]\n",
      "   [0.47058824]]\n",
      "\n",
      "  [[0.59215686]\n",
      "   [0.58431373]\n",
      "   [0.58431373]\n",
      "   ...\n",
      "   [0.47843137]\n",
      "   [0.55294118]\n",
      "   [0.5372549 ]]\n",
      "\n",
      "  [[0.59215686]\n",
      "   [0.59215686]\n",
      "   [0.61176471]\n",
      "   ...\n",
      "   [0.42745098]\n",
      "   [0.48235294]\n",
      "   [0.57254902]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.7372549 ]\n",
      "   [0.7372549 ]\n",
      "   [0.4745098 ]\n",
      "   ...\n",
      "   [0.7254902 ]\n",
      "   [0.7254902 ]\n",
      "   [0.72941176]]\n",
      "\n",
      "  [[0.7372549 ]\n",
      "   [0.73333333]\n",
      "   [0.76862745]\n",
      "   ...\n",
      "   [0.72941176]\n",
      "   [0.71372549]\n",
      "   [0.73333333]]\n",
      "\n",
      "  [[0.72941176]\n",
      "   [0.72156863]\n",
      "   [0.7254902 ]\n",
      "   ...\n",
      "   [0.75686275]\n",
      "   [0.71764706]\n",
      "   [0.72156863]]]\n",
      "\n",
      "\n",
      " [[[0.90588235]\n",
      "   [0.83137255]\n",
      "   [0.61176471]\n",
      "   ...\n",
      "   [0.17254902]\n",
      "   [0.10588235]\n",
      "   [0.0627451 ]]\n",
      "\n",
      "  [[0.89803922]\n",
      "   [0.68627451]\n",
      "   [0.58039216]\n",
      "   ...\n",
      "   [0.10588235]\n",
      "   [0.1372549 ]\n",
      "   [0.10588235]]\n",
      "\n",
      "  [[0.83921569]\n",
      "   [0.61176471]\n",
      "   [0.61568627]\n",
      "   ...\n",
      "   [0.10980392]\n",
      "   [0.08627451]\n",
      "   [0.10980392]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.94509804]\n",
      "   [0.96078431]\n",
      "   [0.98039216]\n",
      "   ...\n",
      "   [0.22352941]\n",
      "   [0.39607843]\n",
      "   [0.57254902]]\n",
      "\n",
      "  [[0.96470588]\n",
      "   [0.98039216]\n",
      "   [0.98823529]\n",
      "   ...\n",
      "   [0.30588235]\n",
      "   [0.41176471]\n",
      "   [0.63529412]]\n",
      "\n",
      "  [[0.98039216]\n",
      "   [0.98431373]\n",
      "   [0.98039216]\n",
      "   ...\n",
      "   [0.34509804]\n",
      "   [0.43137255]\n",
      "   [0.59607843]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.29019608]\n",
      "   [0.31764706]\n",
      "   [0.34117647]\n",
      "   ...\n",
      "   [0.74117647]\n",
      "   [0.74901961]\n",
      "   [0.75294118]]\n",
      "\n",
      "  [[0.30588235]\n",
      "   [0.32156863]\n",
      "   [0.34901961]\n",
      "   ...\n",
      "   [0.7254902 ]\n",
      "   [0.74117647]\n",
      "   [0.75686275]]\n",
      "\n",
      "  [[0.31764706]\n",
      "   [0.3372549 ]\n",
      "   [0.36862745]\n",
      "   ...\n",
      "   [0.69019608]\n",
      "   [0.7254902 ]\n",
      "   [0.75686275]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.35294118]\n",
      "   [0.38823529]\n",
      "   [0.44313725]\n",
      "   ...\n",
      "   [0.75294118]\n",
      "   [0.76470588]\n",
      "   [0.77254902]]\n",
      "\n",
      "  [[0.34509804]\n",
      "   [0.37647059]\n",
      "   [0.44705882]\n",
      "   ...\n",
      "   [0.75294118]\n",
      "   [0.76078431]\n",
      "   [0.75294118]]\n",
      "\n",
      "  [[0.34509804]\n",
      "   [0.38039216]\n",
      "   [0.43137255]\n",
      "   ...\n",
      "   [0.7372549 ]\n",
      "   [0.73333333]\n",
      "   [0.73333333]]]\n",
      "\n",
      "\n",
      " [[[0.87058824]\n",
      "   [0.89019608]\n",
      "   [0.79607843]\n",
      "   ...\n",
      "   [0.54117647]\n",
      "   [0.51764706]\n",
      "   [0.47843137]]\n",
      "\n",
      "  [[0.87058824]\n",
      "   [0.88627451]\n",
      "   [0.79607843]\n",
      "   ...\n",
      "   [0.55686275]\n",
      "   [0.53333333]\n",
      "   [0.49803922]]\n",
      "\n",
      "  [[0.87058824]\n",
      "   [0.88235294]\n",
      "   [0.80784314]\n",
      "   ...\n",
      "   [0.57647059]\n",
      "   [0.56078431]\n",
      "   [0.50588235]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.70196078]\n",
      "   [0.70588235]\n",
      "   [0.69411765]\n",
      "   ...\n",
      "   [0.55294118]\n",
      "   [0.54509804]\n",
      "   [0.5372549 ]]\n",
      "\n",
      "  [[0.7372549 ]\n",
      "   [0.71372549]\n",
      "   [0.69019608]\n",
      "   ...\n",
      "   [0.54117647]\n",
      "   [0.53333333]\n",
      "   [0.52941176]]\n",
      "\n",
      "  [[0.70980392]\n",
      "   [0.65882353]\n",
      "   [0.60784314]\n",
      "   ...\n",
      "   [0.53333333]\n",
      "   [0.53333333]\n",
      "   [0.5254902 ]]]\n",
      "\n",
      "\n",
      " [[[0.76470588]\n",
      "   [0.78039216]\n",
      "   [0.80392157]\n",
      "   ...\n",
      "   [0.71372549]\n",
      "   [0.54901961]\n",
      "   [0.30196078]]\n",
      "\n",
      "  [[0.75686275]\n",
      "   [0.76862745]\n",
      "   [0.79215686]\n",
      "   ...\n",
      "   [0.77254902]\n",
      "   [0.64705882]\n",
      "   [0.41176471]]\n",
      "\n",
      "  [[0.77647059]\n",
      "   [0.78431373]\n",
      "   [0.8       ]\n",
      "   ...\n",
      "   [0.81568627]\n",
      "   [0.76862745]\n",
      "   [0.61568627]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.22352941]\n",
      "   [0.28627451]\n",
      "   [0.32941176]\n",
      "   ...\n",
      "   [0.01176471]\n",
      "   [0.07843137]\n",
      "   [0.12941176]]\n",
      "\n",
      "  [[0.23921569]\n",
      "   [0.28627451]\n",
      "   [0.37647059]\n",
      "   ...\n",
      "   [0.02352941]\n",
      "   [0.0745098 ]\n",
      "   [0.16078431]]\n",
      "\n",
      "  [[0.23921569]\n",
      "   [0.30980392]\n",
      "   [0.37254902]\n",
      "   ...\n",
      "   [0.02352941]\n",
      "   [0.05882353]\n",
      "   [0.14901961]]]]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "[[[[0.99607843]\n",
      "   [0.99607843]\n",
      "   [0.99607843]\n",
      "   ...\n",
      "   [0.0627451 ]\n",
      "   [0.        ]\n",
      "   [0.63137255]]\n",
      "\n",
      "  [[0.99607843]\n",
      "   [0.99607843]\n",
      "   [0.99607843]\n",
      "   ...\n",
      "   [0.06666667]\n",
      "   [0.        ]\n",
      "   [0.47843137]]\n",
      "\n",
      "  [[0.99607843]\n",
      "   [0.99607843]\n",
      "   [0.99607843]\n",
      "   ...\n",
      "   [0.10196078]\n",
      "   [0.        ]\n",
      "   [0.44705882]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.25882353]\n",
      "   [0.3372549 ]\n",
      "   [0.38823529]\n",
      "   ...\n",
      "   [1.        ]\n",
      "   [0.98823529]\n",
      "   [0.99607843]]\n",
      "\n",
      "  [[0.32941176]\n",
      "   [0.36078431]\n",
      "   [0.36078431]\n",
      "   ...\n",
      "   [0.9254902 ]\n",
      "   [1.        ]\n",
      "   [1.        ]]\n",
      "\n",
      "  [[0.36470588]\n",
      "   [0.35294118]\n",
      "   [0.33333333]\n",
      "   ...\n",
      "   [0.16470588]\n",
      "   [0.50588235]\n",
      "   [0.70588235]]]\n",
      "\n",
      "\n",
      " [[[0.61176471]\n",
      "   [0.72156863]\n",
      "   [0.77647059]\n",
      "   ...\n",
      "   [0.61568627]\n",
      "   [0.60392157]\n",
      "   [0.58823529]]\n",
      "\n",
      "  [[0.57254902]\n",
      "   [0.71372549]\n",
      "   [0.78039216]\n",
      "   ...\n",
      "   [0.63137255]\n",
      "   [0.60392157]\n",
      "   [0.58823529]]\n",
      "\n",
      "  [[0.52941176]\n",
      "   [0.69019608]\n",
      "   [0.76470588]\n",
      "   ...\n",
      "   [0.64705882]\n",
      "   [0.63137255]\n",
      "   [0.60784314]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.10980392]\n",
      "   [0.09803922]\n",
      "   [0.08235294]\n",
      "   ...\n",
      "   [0.70196078]\n",
      "   [0.68627451]\n",
      "   [0.67843137]]\n",
      "\n",
      "  [[0.11372549]\n",
      "   [0.07058824]\n",
      "   [0.08627451]\n",
      "   ...\n",
      "   [0.69411765]\n",
      "   [0.6745098 ]\n",
      "   [0.6627451 ]]\n",
      "\n",
      "  [[0.08235294]\n",
      "   [0.05490196]\n",
      "   [0.09019608]\n",
      "   ...\n",
      "   [0.6745098 ]\n",
      "   [0.65490196]\n",
      "   [0.63137255]]]\n",
      "\n",
      "\n",
      " [[[0.27058824]\n",
      "   [0.4627451 ]\n",
      "   [0.23921569]\n",
      "   ...\n",
      "   [0.4627451 ]\n",
      "   [0.48627451]\n",
      "   [0.56470588]]\n",
      "\n",
      "  [[0.25882353]\n",
      "   [0.45098039]\n",
      "   [0.22352941]\n",
      "   ...\n",
      "   [0.50588235]\n",
      "   [0.48235294]\n",
      "   [0.51372549]]\n",
      "\n",
      "  [[0.25098039]\n",
      "   [0.45490196]\n",
      "   [0.23921569]\n",
      "   ...\n",
      "   [0.53333333]\n",
      "   [0.54901961]\n",
      "   [0.53333333]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.44705882]\n",
      "   [0.34117647]\n",
      "   [0.53333333]\n",
      "   ...\n",
      "   [0.38431373]\n",
      "   [0.32941176]\n",
      "   [0.3372549 ]]\n",
      "\n",
      "  [[0.44705882]\n",
      "   [0.33333333]\n",
      "   [0.54901961]\n",
      "   ...\n",
      "   [0.34901961]\n",
      "   [0.32941176]\n",
      "   [0.34509804]]\n",
      "\n",
      "  [[0.44705882]\n",
      "   [0.34117647]\n",
      "   [0.56862745]\n",
      "   ...\n",
      "   [0.34509804]\n",
      "   [0.34117647]\n",
      "   [0.35294118]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.06666667]\n",
      "   [0.06666667]\n",
      "   [0.0627451 ]\n",
      "   ...\n",
      "   [0.3254902 ]\n",
      "   [0.44705882]\n",
      "   [0.96078431]]\n",
      "\n",
      "  [[0.07058824]\n",
      "   [0.06666667]\n",
      "   [0.0627451 ]\n",
      "   ...\n",
      "   [0.40784314]\n",
      "   [0.53333333]\n",
      "   [0.99215686]]\n",
      "\n",
      "  [[0.0745098 ]\n",
      "   [0.0627451 ]\n",
      "   [0.06666667]\n",
      "   ...\n",
      "   [0.50196078]\n",
      "   [0.59607843]\n",
      "   [1.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.01568627]\n",
      "   [0.08235294]\n",
      "   [0.18039216]\n",
      "   ...\n",
      "   [0.72941176]\n",
      "   [0.70588235]\n",
      "   [0.73333333]]\n",
      "\n",
      "  [[0.01960784]\n",
      "   [0.06666667]\n",
      "   [0.16078431]\n",
      "   ...\n",
      "   [0.69411765]\n",
      "   [0.6745098 ]\n",
      "   [0.69019608]]\n",
      "\n",
      "  [[0.07843137]\n",
      "   [0.05882353]\n",
      "   [0.08627451]\n",
      "   ...\n",
      "   [0.60392157]\n",
      "   [0.52156863]\n",
      "   [0.44313725]]]\n",
      "\n",
      "\n",
      " [[[0.11764706]\n",
      "   [0.10980392]\n",
      "   [0.10980392]\n",
      "   ...\n",
      "   [0.23529412]\n",
      "   [0.19607843]\n",
      "   [0.17254902]]\n",
      "\n",
      "  [[0.11764706]\n",
      "   [0.10588235]\n",
      "   [0.10980392]\n",
      "   ...\n",
      "   [0.25098039]\n",
      "   [0.20392157]\n",
      "   [0.15686275]]\n",
      "\n",
      "  [[0.12156863]\n",
      "   [0.10980392]\n",
      "   [0.11764706]\n",
      "   ...\n",
      "   [0.23921569]\n",
      "   [0.21176471]\n",
      "   [0.14509804]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.40784314]\n",
      "   [0.42745098]\n",
      "   [0.43137255]\n",
      "   ...\n",
      "   [0.1372549 ]\n",
      "   [0.11764706]\n",
      "   [0.11764706]]\n",
      "\n",
      "  [[0.4       ]\n",
      "   [0.41176471]\n",
      "   [0.42352941]\n",
      "   ...\n",
      "   [0.1372549 ]\n",
      "   [0.12156863]\n",
      "   [0.11372549]]\n",
      "\n",
      "  [[0.36470588]\n",
      "   [0.37647059]\n",
      "   [0.39215686]\n",
      "   ...\n",
      "   [0.1372549 ]\n",
      "   [0.11764706]\n",
      "   [0.10980392]]]\n",
      "\n",
      "\n",
      " [[[0.0745098 ]\n",
      "   [0.05098039]\n",
      "   [0.05490196]\n",
      "   ...\n",
      "   [0.42352941]\n",
      "   [0.37254902]\n",
      "   [0.3372549 ]]\n",
      "\n",
      "  [[0.0627451 ]\n",
      "   [0.06666667]\n",
      "   [0.05882353]\n",
      "   ...\n",
      "   [0.41176471]\n",
      "   [0.36862745]\n",
      "   [0.35294118]]\n",
      "\n",
      "  [[0.03921569]\n",
      "   [0.03529412]\n",
      "   [0.03921569]\n",
      "   ...\n",
      "   [0.39607843]\n",
      "   [0.36470588]\n",
      "   [0.37254902]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.07058824]\n",
      "   [0.05490196]\n",
      "   [0.0627451 ]\n",
      "   ...\n",
      "   [0.21568627]\n",
      "   [0.25098039]\n",
      "   [0.37254902]]\n",
      "\n",
      "  [[0.05882353]\n",
      "   [0.05882353]\n",
      "   [0.05098039]\n",
      "   ...\n",
      "   [0.48235294]\n",
      "   [0.67058824]\n",
      "   [0.75294118]]\n",
      "\n",
      "  [[0.0627451 ]\n",
      "   [0.05490196]\n",
      "   [0.05098039]\n",
      "   ...\n",
      "   [0.74117647]\n",
      "   [0.78039216]\n",
      "   [0.78823529]]]]\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = prepare_data(train)\n",
    "X_test, y_test = prepare_data(test)\n",
    "\n",
    "print(X_train)\n",
    "print(y_train[0])\n",
    "print(X_test)\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 46, 46, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 44, 44, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 22, 22, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 20, 20, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 9, 9, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 5, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 1,541,831\n",
      "Trainable params: 1,540,935\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model = Sequential()\n",
    "\n",
    "cnn_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "cnn_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "cnn_model.add(Dropout(0.25))\n",
    "cnn_model.add(BatchNormalization())\n",
    "\n",
    "cnn_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "cnn_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "cnn_model.add(Dropout(0.25))\n",
    "cnn_model.add(BatchNormalization())\n",
    "\n",
    "cnn_model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "cnn_model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(BatchNormalization())\n",
    "\n",
    "cnn_model.add(Flatten())\n",
    "\n",
    "cnn_model.add(Dense(256, activation='relu'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(256, activation='relu'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(256, activation='relu'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "\n",
    "cnn_model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "cnn_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "449/449 [==============================] - 441s 981ms/step - loss: 2.0366 - accuracy: 0.1998 - val_loss: 1.8330 - val_accuracy: 0.2320\n",
      "Epoch 2/50\n",
      "449/449 [==============================] - 433s 964ms/step - loss: 1.8191 - accuracy: 0.2383 - val_loss: 1.8016 - val_accuracy: 0.2469\n",
      "Epoch 3/50\n",
      "449/449 [==============================] - 433s 963ms/step - loss: 1.7842 - accuracy: 0.2552 - val_loss: 1.7677 - val_accuracy: 0.2675\n",
      "Epoch 4/50\n",
      "449/449 [==============================] - 434s 967ms/step - loss: 1.6950 - accuracy: 0.3102 - val_loss: 1.6370 - val_accuracy: 0.3522\n",
      "Epoch 5/50\n",
      "449/449 [==============================] - 433s 965ms/step - loss: 1.5687 - accuracy: 0.3741 - val_loss: 1.5148 - val_accuracy: 0.4341\n",
      "Epoch 6/50\n",
      "449/449 [==============================] - 434s 966ms/step - loss: 1.4959 - accuracy: 0.4156 - val_loss: 1.4772 - val_accuracy: 0.4494\n",
      "Epoch 7/50\n",
      "449/449 [==============================] - 433s 964ms/step - loss: 1.4187 - accuracy: 0.4543 - val_loss: 1.3496 - val_accuracy: 0.4763\n",
      "Epoch 8/50\n",
      "449/449 [==============================] - 431s 961ms/step - loss: 1.3766 - accuracy: 0.4755 - val_loss: 1.2924 - val_accuracy: 0.5084\n",
      "Epoch 9/50\n",
      "449/449 [==============================] - 429s 956ms/step - loss: 1.3215 - accuracy: 0.4989 - val_loss: 1.2722 - val_accuracy: 0.5259\n",
      "Epoch 10/50\n",
      "449/449 [==============================] - 433s 964ms/step - loss: 1.2964 - accuracy: 0.5061 - val_loss: 1.2717 - val_accuracy: 0.5196\n",
      "Epoch 11/50\n",
      "449/449 [==============================] - 432s 962ms/step - loss: 1.2841 - accuracy: 0.5169 - val_loss: 1.2412 - val_accuracy: 0.5358\n",
      "Epoch 12/50\n",
      "449/449 [==============================] - 431s 960ms/step - loss: 1.2448 - accuracy: 0.5286 - val_loss: 1.2176 - val_accuracy: 0.5513\n",
      "Epoch 13/50\n",
      "449/449 [==============================] - 433s 965ms/step - loss: 1.2342 - accuracy: 0.5359 - val_loss: 1.2375 - val_accuracy: 0.5322\n",
      "Epoch 14/50\n",
      "449/449 [==============================] - 432s 962ms/step - loss: 1.2068 - accuracy: 0.5474 - val_loss: 1.3082 - val_accuracy: 0.5124\n",
      "Epoch 15/50\n",
      "449/449 [==============================] - 433s 963ms/step - loss: 1.1859 - accuracy: 0.5618 - val_loss: 1.1535 - val_accuracy: 0.5769\n",
      "Epoch 16/50\n",
      "449/449 [==============================] - 433s 965ms/step - loss: 1.1691 - accuracy: 0.5647 - val_loss: 1.1735 - val_accuracy: 0.5684\n",
      "Epoch 17/50\n",
      "449/449 [==============================] - 432s 963ms/step - loss: 1.1620 - accuracy: 0.5733 - val_loss: 1.1432 - val_accuracy: 0.5671\n",
      "Epoch 18/50\n",
      "449/449 [==============================] - 433s 963ms/step - loss: 1.1401 - accuracy: 0.5710 - val_loss: 1.1774 - val_accuracy: 0.5541\n",
      "Epoch 19/50\n",
      "449/449 [==============================] - 431s 959ms/step - loss: 1.1200 - accuracy: 0.5871 - val_loss: 1.1115 - val_accuracy: 0.5903\n",
      "Epoch 20/50\n",
      "449/449 [==============================] - 430s 957ms/step - loss: 1.1173 - accuracy: 0.5791 - val_loss: 1.1239 - val_accuracy: 0.5839\n",
      "Epoch 21/50\n",
      "449/449 [==============================] - 436s 971ms/step - loss: 1.0945 - accuracy: 0.5962 - val_loss: 1.1244 - val_accuracy: 0.5811\n",
      "Epoch 22/50\n",
      "449/449 [==============================] - 430s 958ms/step - loss: 1.0863 - accuracy: 0.6043 - val_loss: 1.1182 - val_accuracy: 0.5782\n",
      "Epoch 23/50\n",
      "449/449 [==============================] - 434s 967ms/step - loss: 1.0551 - accuracy: 0.6075 - val_loss: 1.1102 - val_accuracy: 0.5904\n",
      "Epoch 24/50\n",
      "449/449 [==============================] - 436s 971ms/step - loss: 1.0399 - accuracy: 0.6175 - val_loss: 1.0810 - val_accuracy: 0.5952\n",
      "Epoch 25/50\n",
      "449/449 [==============================] - 430s 957ms/step - loss: 1.0399 - accuracy: 0.6146 - val_loss: 1.0865 - val_accuracy: 0.5925\n",
      "Epoch 26/50\n",
      "449/449 [==============================] - 428s 953ms/step - loss: 1.0106 - accuracy: 0.6266 - val_loss: 1.0628 - val_accuracy: 0.6037\n",
      "Epoch 27/50\n",
      "449/449 [==============================] - 428s 953ms/step - loss: 1.0036 - accuracy: 0.6338 - val_loss: 1.0565 - val_accuracy: 0.6131\n",
      "Epoch 28/50\n",
      "449/449 [==============================] - 427s 952ms/step - loss: 0.9871 - accuracy: 0.6383 - val_loss: 1.0546 - val_accuracy: 0.6094\n",
      "Epoch 29/50\n",
      "449/449 [==============================] - 430s 959ms/step - loss: 0.9758 - accuracy: 0.6429 - val_loss: 1.0655 - val_accuracy: 0.5997\n",
      "Epoch 30/50\n",
      "449/449 [==============================] - 428s 954ms/step - loss: 0.9536 - accuracy: 0.6508 - val_loss: 1.0792 - val_accuracy: 0.6010\n",
      "Epoch 31/50\n",
      "449/449 [==============================] - 424s 944ms/step - loss: 0.9364 - accuracy: 0.6590 - val_loss: 1.0594 - val_accuracy: 0.6020\n",
      "Epoch 32/50\n",
      "449/449 [==============================] - 425s 946ms/step - loss: 0.9206 - accuracy: 0.6632 - val_loss: 1.0797 - val_accuracy: 0.5997\n",
      "Epoch 33/50\n",
      "449/449 [==============================] - 425s 947ms/step - loss: 0.9231 - accuracy: 0.6612 - val_loss: 1.0599 - val_accuracy: 0.6094\n",
      "Epoch 34/50\n",
      "449/449 [==============================] - 426s 948ms/step - loss: 0.9090 - accuracy: 0.6689 - val_loss: 1.0748 - val_accuracy: 0.6043\n",
      "Epoch 35/50\n",
      "449/449 [==============================] - 427s 951ms/step - loss: 0.9048 - accuracy: 0.6718 - val_loss: 1.0616 - val_accuracy: 0.6055\n",
      "Epoch 36/50\n",
      "449/449 [==============================] - 425s 946ms/step - loss: 0.8794 - accuracy: 0.6813 - val_loss: 1.0549 - val_accuracy: 0.6120\n",
      "Epoch 37/50\n",
      "449/449 [==============================] - 425s 946ms/step - loss: 0.8891 - accuracy: 0.6849 - val_loss: 1.0597 - val_accuracy: 0.6091\n",
      "Epoch 38/50\n",
      "449/449 [==============================] - 427s 951ms/step - loss: 0.8682 - accuracy: 0.6829 - val_loss: 1.0506 - val_accuracy: 0.6147\n",
      "Epoch 39/50\n",
      "449/449 [==============================] - 426s 949ms/step - loss: 0.8710 - accuracy: 0.6825 - val_loss: 1.0492 - val_accuracy: 0.6162\n",
      "Epoch 40/50\n",
      "449/449 [==============================] - 427s 950ms/step - loss: 0.8522 - accuracy: 0.6928 - val_loss: 1.0464 - val_accuracy: 0.6199\n",
      "Epoch 41/50\n",
      "449/449 [==============================] - 427s 950ms/step - loss: 0.8379 - accuracy: 0.6945 - val_loss: 1.0780 - val_accuracy: 0.6082\n",
      "Epoch 42/50\n",
      "449/449 [==============================] - 427s 951ms/step - loss: 0.8373 - accuracy: 0.6962 - val_loss: 1.0397 - val_accuracy: 0.6154\n",
      "Epoch 43/50\n",
      "449/449 [==============================] - 427s 952ms/step - loss: 0.8412 - accuracy: 0.6948 - val_loss: 1.0628 - val_accuracy: 0.6137\n",
      "Epoch 44/50\n",
      "449/449 [==============================] - 426s 948ms/step - loss: 0.8102 - accuracy: 0.7092 - val_loss: 1.0271 - val_accuracy: 0.6250\n",
      "Epoch 45/50\n",
      "449/449 [==============================] - 424s 943ms/step - loss: 0.7980 - accuracy: 0.7092 - val_loss: 1.0320 - val_accuracy: 0.6241\n",
      "Epoch 46/50\n",
      "449/449 [==============================] - 425s 948ms/step - loss: 0.7975 - accuracy: 0.7082 - val_loss: 1.0418 - val_accuracy: 0.6233\n",
      "Epoch 47/50\n",
      "449/449 [==============================] - 425s 946ms/step - loss: 0.7865 - accuracy: 0.7180 - val_loss: 1.0777 - val_accuracy: 0.6158\n",
      "Epoch 48/50\n",
      "449/449 [==============================] - 425s 946ms/step - loss: 0.7931 - accuracy: 0.7137 - val_loss: 1.0404 - val_accuracy: 0.6180\n",
      "Epoch 49/50\n",
      "449/449 [==============================] - 425s 946ms/step - loss: 0.7849 - accuracy: 0.7189 - val_loss: 1.0558 - val_accuracy: 0.6167\n",
      "Epoch 50/50\n",
      "449/449 [==============================] - 426s 948ms/step - loss: 0.7679 - accuracy: 0.7248 - val_loss: 1.0294 - val_accuracy: 0.6286\n",
      "CPU times: user 18h 40min 22s, sys: 1h 53min 21s, total: 20h 33min 44s\n",
      "Wall time: 5h 57min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "h1 = cnn_model.fit(X_train, y_train, batch_size=64, epochs=50, verbose=1, \n",
    "                   validation_data =(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_json = cnn_model.to_json()\n",
    "with open(\"cnn_model3.json\", \"w\") as json_file:\n",
    "    json_file.write(cnn_model_json)\n",
    "cnn_model.save_weights(\"cnn_model3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.8272259e-01 4.3034248e-02 2.3943886e-01 ... 3.0733800e-01\n",
      "  1.4165446e-02 9.9614091e-02]\n",
      " [2.1229848e-01 8.4461056e-02 2.9325670e-01 ... 2.5992993e-01\n",
      "  2.7148355e-02 7.4510492e-02]\n",
      " [7.8519589e-01 2.6815627e-02 6.3302711e-02 ... 9.0427905e-02\n",
      "  1.8299579e-04 3.4012523e-02]\n",
      " ...\n",
      " [1.6122918e-01 9.1589550e-03 1.1666897e-01 ... 1.7394981e-01\n",
      "  2.5857707e-02 1.9119185e-01]\n",
      " [7.4275680e-02 4.8887817e-04 2.7614560e-02 ... 3.9339799e-02\n",
      "  9.8874941e-03 6.5787412e-02]\n",
      " [1.3546652e-01 4.6968907e-02 3.4052688e-01 ... 4.0111631e-01\n",
      "  1.2373685e-02 5.4276325e-02]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(cnn_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
